{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sec0'></a>\n",
    "# Visualization of datasets in the BoW and Tf-Idf space using the nlp13 corpora\n",
    "Idea is to use PCA and possibly tSNE to reduce the dimension of the text features represented as BoW and Tf-Idf vectors and visualize each dataset-specific document in 2D or 3D space. They can be colored by different kinds of lables (e.g. experiment types, quantification methods, species, etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. <a href='#sec1'><b>Import Modules</b></a>\n",
    "2. <a href='#sec2'><b>Import and Process Data</b></a>\n",
    "3. <a href='#sec3'><b>Set up data processing functions</b></a>\n",
    "4. <a href='#sec4'><b>Set up visualization functions</b></a>\n",
    "5. <a href='#sec5'><b>Visualize in PCA space</b></a>\n",
    "6. <a href='#sec6'><b>Visualize in tSNE space</b></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sec1'></a>\n",
    "## Import Modules\n",
    "<a href='#sec0'>(Back to top)</a><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import spacy\n",
    "from gensim import corpora, models\n",
    "from gensim import matutils\n",
    "from nlp_utility import lemmatize_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sec2'></a>\n",
    "## Import and Process Data\n",
    "<a href='#sec0'>(Back to top)</a><br>\n",
    "1. <a href='#sec2-1'>Create DataFrames</a><br>\n",
    "2. <a href='#sec2-2'>Create Dictionary and BoW & Tf-Idf corpora</a><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sec2-1'></a><b>1. Create DataFrames</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I need to create new copora because I realized 1) in nlp13, .dropna() was applied to remove rows whose 'quant_methods' was null, and 2) consequently the corpora were specific to the remaining subset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# rows: 5496\n",
      "# rows: 4390\n"
     ]
    }
   ],
   "source": [
    "# Import DataFrame\n",
    "if False:\n",
    "    df = pd.read_csv('base_data/pride_table.csv').astype(str)\n",
    "    print('# rows:', len(df))\n",
    "\n",
    "    df.loc[:, 'sample_protocol'] = df.loc[:, 'sample_protocol'].replace({'Not available': np.NaN, 'nan':np.NaN})\n",
    "    df.loc[:, 'data_protocol'] = df.loc[:, 'data_protocol'].replace({'Not available': np.NaN, 'nan':np.NaN})\n",
    "    df.loc[:, 'description'] = df.loc[:, 'description'].replace({'Not available': np.NaN, 'nan':np.NaN})\n",
    "\n",
    "    # Drop rows that have null text fields\n",
    "    df.dropna(subset=['sample_protocol', 'data_protocol', 'description'], inplace=True)\n",
    "    print('# rows:', len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sample_protocol...\n",
      "Processing data_protocol...\n",
      "Processing description...\n",
      "CPU times: user 50min 33s, sys: 47min 52s, total: 1h 38min 25s\n",
      "Wall time: 12min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# lemmatize text\n",
    "if False:\n",
    "    print('Processing sample_protocol...')\n",
    "    df.loc[:, 'sample_protocol'] = df.loc[:, 'sample_protocol'].apply(lambda x: lemmatize_text(x))\n",
    "    \n",
    "    print('Processing data_protocol...')\n",
    "    df.loc[:, 'data_protocol'] = df.loc[:, 'data_protocol'].apply(lambda x: lemmatize_text(x))\n",
    "    \n",
    "    print('Processing description...')\n",
    "    df.loc[:, 'description'] = df.loc[:, 'description'].apply(lambda x: lemmatize_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feature specific DFs and save\n",
    "if False:\n",
    "    inst_df = df[['dataset_id', 'sample_protocol', 'data_protocol', 'description', 'instruments']].dropna()\n",
    "    exp_df = df[['dataset_id', 'sample_protocol', 'data_protocol', 'description', 'exp_types']].dropna()\n",
    "    pi_df = df[['dataset_id', 'sample_protocol', 'data_protocol', 'description', 'labhead_fullname']].dropna()\n",
    "\n",
    "    with open('nlp14_data/dfs/all_fields_df.pickle', 'wb') as out_df:\n",
    "        pickle.dump(df, out_df)\n",
    "    \n",
    "    with open('nlp14_data/dfs/instruments_df.pickle', 'wb') as out_df:\n",
    "        pickle.dump(inst_df, out_df)\n",
    "    \n",
    "    with open('nlp14_data/dfs/exp_types_df.pickle', 'wb') as out_df:\n",
    "        pickle.dump(exp_df, out_df)\n",
    "    \n",
    "    with open('nlp14_data/dfs/pis_df.pickle', 'wb') as out_df:\n",
    "        pickle.dump(pi_df, out_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_id</th>\n",
       "      <th>sample_protocol</th>\n",
       "      <th>data_protocol</th>\n",
       "      <th>description</th>\n",
       "      <th>instruments</th>\n",
       "      <th>exp_types</th>\n",
       "      <th>quant_methods</th>\n",
       "      <th>labhead_fullname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PXD000011</td>\n",
       "      <td>[the, crude, membrane, tap, mouse, forebrain, ...</td>\n",
       "      <td>[data, dependent, analysis, carry, use, resolu...</td>\n",
       "      <td>[tap, kda, mda, mda, wt, control, mda, native,...</td>\n",
       "      <td>LTQ Orbitrap, instrument model</td>\n",
       "      <td>Bottom-up proteomics</td>\n",
       "      <td>nan</td>\n",
       "      <td>Seth Grant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>PXD000029</td>\n",
       "      <td>[breast, cancer, tissue, lysate, reduction, al...</td>\n",
       "      <td>[proteomic, datum, analysis, proteome, discove...</td>\n",
       "      <td>[current, prognostic, factor, insufficient, pr...</td>\n",
       "      <td>LTQ Orbitrap Velos</td>\n",
       "      <td>Shotgun proteomics</td>\n",
       "      <td>iTRAQ</td>\n",
       "      <td>Pavel Bouchal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>PXD000041</td>\n",
       "      <td>[gel, digest, perform, describe, standard, pro...</td>\n",
       "      <td>[the, result, spectra, analyze, mascot, matrix...</td>\n",
       "      <td>[schizosaccharomyces, pombe, eukaryotic, genom...</td>\n",
       "      <td>LTQ Orbitrap, instrument model</td>\n",
       "      <td>Bottom-up proteomics</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset_id                                    sample_protocol  \\\n",
       "8   PXD000011  [the, crude, membrane, tap, mouse, forebrain, ...   \n",
       "23  PXD000029  [breast, cancer, tissue, lysate, reduction, al...   \n",
       "31  PXD000041  [gel, digest, perform, describe, standard, pro...   \n",
       "\n",
       "                                        data_protocol  \\\n",
       "8   [data, dependent, analysis, carry, use, resolu...   \n",
       "23  [proteomic, datum, analysis, proteome, discove...   \n",
       "31  [the, result, spectra, analyze, mascot, matrix...   \n",
       "\n",
       "                                          description  \\\n",
       "8   [tap, kda, mda, mda, wt, control, mda, native,...   \n",
       "23  [current, prognostic, factor, insufficient, pr...   \n",
       "31  [schizosaccharomyces, pombe, eukaryotic, genom...   \n",
       "\n",
       "                       instruments             exp_types quant_methods  \\\n",
       "8   LTQ Orbitrap, instrument model  Bottom-up proteomics           nan   \n",
       "23              LTQ Orbitrap Velos    Shotgun proteomics         iTRAQ   \n",
       "31  LTQ Orbitrap, instrument model  Bottom-up proteomics           nan   \n",
       "\n",
       "   labhead_fullname  \n",
       "8        Seth Grant  \n",
       "23    Pavel Bouchal  \n",
       "31              nan  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the corpora\n",
    "# This time I'll only use combined protocols and that combined with description field (i.e. two corpora)\n",
    "if False:\n",
    "    # Protocols combined\n",
    "    protocols_corpus = list(df.sample_protocol + df.data_protocol)\n",
    "    with open('nlp14_data/corpora/protocols_corpus.pickle', 'wb') as outfile:\n",
    "        pickle.dump(protocols_corpus, outfile)\n",
    "\n",
    "    # All combined\n",
    "    whole_corpus = list(df.sample_protocol + df.data_protocol + df.description)\n",
    "    with open('nlp14_data/corpora/whole_corpus.pickle', 'wb') as outfile:\n",
    "        pickle.dump(whole_corpus, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sec2-2'></a><b>2. Create Dictionary and BoW & Tf-Idf corpora</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load serialized corpora\n",
    "if False:\n",
    "    # Protocols combined\n",
    "    with open('nlp14_data/corpora/protocols_corpus.pickle', 'rb') as infile:\n",
    "        protocols_corpus = pickle.load(infile)\n",
    "\n",
    "    # All combined\n",
    "    with open('nlp14_data/corpora/whole_corpus.pickle', 'rb') as infile:\n",
    "        whole_corpus = pickle.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and save dictionary using whole_corpus\n",
    "if False:\n",
    "    my_dictionary = corpora.Dictionary(whole_corpus)\n",
    "    my_dictionary.save('nlp14_data/whole_dictionary.dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save BoW and Tf-Idf\n",
    "if False:\n",
    "    # BoW transformations and save\n",
    "    protocols_bow = [my_dictionary.doc2bow(text) for text in protocols_corpus]\n",
    "    whole_bow = [my_dictionary.doc2bow(text) for text in whole_corpus]\n",
    "    corpora.MmCorpus.serialize('nlp14_data/bow_and_tfidf/protocols_bow.mm', protocols_bow)\n",
    "    corpora.MmCorpus.serialize('nlp14_data/bow_and_tfidf/whole_bow.mm', whole_bow)\n",
    "    \n",
    "    # Tf-Idf transformations  and save\n",
    "    protocols_tfidf_model = models.TfidfModel(protocols_bow)\n",
    "    protocols_tfidf = protocols_tfidf_model[protocols_bow]\n",
    "    corpora.MmCorpus.serialize('nlp14_data/bow_and_tfidf/protocols_tfidf.mm', protocols_tfidf)\n",
    "    \n",
    "    whole_tfidf_model = models.TfidfModel(whole_bow)\n",
    "    whole_tfidf = whole_tfidf_model[whole_bow]\n",
    "    corpora.MmCorpus.serialize('nlp14_data/bow_and_tfidf/whole_tfidf.mm', whole_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sec3'></a>\n",
    "## Set up data processing functions\n",
    "<a href='#sec0'>(Back to top)</a><br>\n",
    "1. Label encoding function\n",
    "    - Sort categories by number of appearances\n",
    "    - Keep top 5 in the ranking, rename all others as 'others'\n",
    "    - Use LabelEncoder from sklearn to convert them to integers\n",
    "    - Return one dimensional vector with the same shape as y\n",
    "2. PCA transformation function\n",
    "    - Takes in the whole feature space\n",
    "    - PCA with n_components = 3\n",
    "    - Return comp0, comp1, comp3\n",
    "3. tSNE transformation function\n",
    "    - Takes in the whole feature space\n",
    "    - tSNE with n_components = 2\n",
    "    - Return comp0, comp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sec4'></a>\n",
    "## Set up visualization functions\n",
    "<a href='#sec0'>(Back to top)</a><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sec5'></a>\n",
    "## Visualize in PCA space\n",
    "<a href='#sec0'>(Back to top)</a><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sec6'></a>\n",
    "## Visualize in tSNE space\n",
    "<a href='#sec0'>(Back to top)</a><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sec'></a>\n",
    "## TEMPLETE\n",
    "<a href='#sec0'>(Back to top)</a><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
