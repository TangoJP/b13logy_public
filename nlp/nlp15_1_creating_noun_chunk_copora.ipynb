{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sec0'></a>\n",
    "# Creating more features using Noun Chunks via Spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In nlp13 notebooks, unigrams (or single words) were used as features for classifying quantification methods. In some cases where one or a few words clearly signify the quatn. methods used (e.g. silac, itraq), unigram features worked very well. However, they did not work well for other ones, including 'label free' and 'spectrum counting.' Here, I'm trying 'noun chunks' as features (alternatively bi- and tri-grams could be used). Rationale being, 'phrases' that lost meaning in the unigram form will be retained in this approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. <a href='#sec1'><b>Import Modules</b></a>\n",
    "2. <a href='#sec2'><b>Import and Pre-rocess Data</b></a>\n",
    "3. <a href='#sec3'><b>Extract Noun Chunks</b></a>\n",
    "4. <a href='#sec4'><b>4. Crate Dictionary and BoW & Tf-Idf corpora</b></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sec1'></a>\n",
    "## 1. Import and Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import spacy\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import spacy\n",
    "from gensim import corpora, models\n",
    "from gensim import matutils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sec2'></a>\n",
    "## 2. Import and Pre-process Data\n",
    "<a href='#sec0'>(Back to top)</a><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# rows initially: 5496\n",
      "# rows after dropna: 4390\n"
     ]
    }
   ],
   "source": [
    "# Import DataFrame and drop rows that do not have texts\n",
    "if True:\n",
    "    df = pd.read_csv('base_data/pride_table.csv').astype(str)\n",
    "    print('# rows initially:', len(df))\n",
    "    \n",
    "    # Replace 'Not available' texts with NaN\n",
    "    df.loc[:, 'sample_protocol'] = df.loc[:, 'sample_protocol'].replace({'Not available': np.NaN, 'nan':np.NaN})\n",
    "    df.loc[:, 'data_protocol'] = df.loc[:, 'data_protocol'].replace({'Not available': np.NaN, 'nan':np.NaN})\n",
    "    df.loc[:, 'description'] = df.loc[:, 'description'].replace({'Not available': np.NaN, 'nan':np.NaN})\n",
    "\n",
    "    # Drop rows that have null text fields\n",
    "    df.dropna(subset=['sample_protocol', 'data_protocol', 'description'], inplace=True)\n",
    "    print('# rows after dropna:', len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sec3'></a>\n",
    "## 3. Extract Noun Chuncks\n",
    "<a href='#sec0'>(Back to top)</a><br>\n",
    "1. <a href='#sec3-1'>Create and test extraction method</a><br>\n",
    "2. <a href='#sec3-2'>2. Create DataFrame with Noun Chunks</a><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sec3-1'></a><b>1. Create and test extraction method</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to extract noun chuncks for a document\n",
    "# * This function will require some tuning later for processing text\n",
    "# * Ex1: replace hyphen with a space\n",
    "# * Ex2: removes words like 'which'\n",
    "def extract_noun_chuncks(text):\n",
    "    pattern = r'^a\\s|^an\\s|^the\\s|^each\\s|^only\\s|\\.$|^\\(|\\)$| analysis$| analyses$|,'    # patterns to drop\n",
    "    mz_pattern1 = r'^/z'    # Regex for fixing 'm/z' cases\n",
    "    mz_pattern2 = r' m$'   # Regex for fixing 'm/z' cases\n",
    "    \n",
    "    doc = nlp(text)    # Create nlp doc object\n",
    "    noun_chuncks = [chunk.text.lower() for chunk in doc.noun_chunks]        # Get noun_chunks\n",
    "    noun_chuncks = [re.sub(pattern, '', chunk) for chunk in noun_chuncks]   # Remove some patterns\n",
    "    noun_chuncks = [chunk for chunk in noun_chuncks if not re.match(mz_pattern1, chunk)]    # Remoe '/z' strings\n",
    "    noun_chuncks = [re.sub(mz_pattern2, ' m/z', chunk) for chunk in noun_chuncks]\n",
    "    noun_chuncks = [chunk.strip() for chunk in noun_chuncks]\n",
    "    \n",
    "    return noun_chuncks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Generation of mDia2-Based Immunocomplexes and Mass Spectrometry 293T cells were transfected with Flag-tagged full-length mDia2 (either the wild type or the MA mutant) or empty vector. Cell lysates were prepared as previously described (7, 19). One and a half milligrams of cell lysates were immunoprecipitated using anti-Flag M2® Affinity gel (Sigma-Aldrich) for 2 hours at 4°C. Beads were washed three times in NET buffer (50 mM Tris-HCl pH 7.6, 150 mM NaCl, 5 mM EDTA and 0.1% Triton X-100) supplemented with protease inhibitor cocktail (Roche), 5 mM NaF and 1 mM NaVO4. Proteins were eluted with Laemmli buffer and separated by SDS-PAGE (NuPage 4-12% Bis-Tris gradient gel (Invitrogen)). The gel was fixed and stained with Colloidal Blue according to manufacturer’s instructions (Invitrogen).   Mass Spectrometry Protein reduction and alkylation was performed in gel with DTT (56°C, 1 h) and 2-chloro-iodoacetamide (dark, RT, 30 min), respectively, after which digestion was performed with trypsin over night at 37°C. Peptides were extracted with 100% ACN. The samples were analysed on an LTQ Orbitrap or LTQ OrbitrapVelos instrument (Thermo Scientific, Bremen) connected to an Agilent 1200 HPLC system. The nanoLC was equipped with a 20 mm 100 µm i.d.Reprosil C18 trap column and a 400 mm 50 µm i.d.Reprosil C18 analytical column (Dr Maisch, Ammerbuch-Entringen, Germany) all packed in-house. Solvent A consisted of 0.1M acetic acid (Merck) in deionized water (Milli-Q, Millipore), and solvent B consisted of 0.1M acetic acid in 80% acetonitrile (Biosolve). Trapping was performed at a flow of 5 µl/min for 10 min and the fractions were eluted using a flow rate passively split to either 100 nl/min (60 min LC method) or 50 nl/min (90 min LC method). The gradient used was: 90 min LC method, 10 min solvent A; 13-28% solvent B in 45 min; 28-50% solvent B in 10 min; 50-100% solvent B in 3 min; 100% solvent B for 1 min; 20 min solvent A. The mass spectrometer was operated in positive ion mode and in data-dependent mode to automatically switch between MS and MS/MS. For the Orbitrap analysis the three most intense ions in the survey scan (350 to 1500 m/z, resolution 60, 000, AGC target 5e5) were fragmented in the linear ion trap (AGC target 1e4), and for the OrbitrapVelos analysis the five most intense ions in the survey scan (350 to 1500 m/z, resolution 30, 000, AGC target 5e5) were subjected to HCD fragmentation (resolution 7,500, AGC target 3e4), with the normalized collision energy set to 35% for both CID and HCD. The signal threshold for triggering an MS/MS event was set to 500 counts. For internal mass calibration the 445.120025 ion was used as lock mass with a target lock mass abundance of 0%. The low mass cut-off for HCD was set to 180 m/z. Charge state screening was enabled, and precursors with unknown charge state or a charge state of 1 were excluded. Dynamic exclusion was enabled (exclusion size list 500, exclusion duration 25 s).'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text = df.sample_protocol.loc[139]\n",
    "test_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0%',\n",
       " '0.1%',\n",
       " '0.1m acetic acid',\n",
       " '0.1m acetic acid',\n",
       " '1 h',\n",
       " '1 min',\n",
       " '1 mm navo4',\n",
       " '10 min',\n",
       " '10 min',\n",
       " '10 min solvent a',\n",
       " '100% acn',\n",
       " '100% solvent b',\n",
       " '13-28% solvent b',\n",
       " '150 mm nacl',\n",
       " '180 m/z',\n",
       " '2 hours',\n",
       " '2-chloro-iodoacetamide',\n",
       " '20 min',\n",
       " '20 mm',\n",
       " '25 s',\n",
       " '28-50% solvent b',\n",
       " '3 min',\n",
       " '30 min',\n",
       " '35%',\n",
       " '350 to 1500 m/z',\n",
       " '350 to 1500 m/z',\n",
       " '37°c',\n",
       " '4-12% bis-tris gradient gel',\n",
       " '400 mm',\n",
       " '445.120025 ion',\n",
       " '45 min',\n",
       " '4°c',\n",
       " '5 mm edta',\n",
       " '5 mm naf',\n",
       " '5 µl/min',\n",
       " '50 mm tris-hcl ph',\n",
       " '50 nl/min',\n",
       " '50-100% solvent b',\n",
       " '500 counts',\n",
       " '56°c',\n",
       " '60 min lc method',\n",
       " '80% acetonitrile',\n",
       " '90 min lc method',\n",
       " '90 min lc method',\n",
       " 'affinity gel',\n",
       " 'agc',\n",
       " 'agc',\n",
       " 'agc',\n",
       " 'agc',\n",
       " 'agilent 1200 hplc system',\n",
       " 'alkylation',\n",
       " 'ammerbuch-entringen',\n",
       " 'beads',\n",
       " 'biosolve',\n",
       " 'both cid',\n",
       " 'cell lysates',\n",
       " 'cell lysates',\n",
       " 'charge state',\n",
       " 'charge state screening',\n",
       " 'colloidal blue',\n",
       " 'data-dependent mode',\n",
       " 'deionized water',\n",
       " 'dr maisch',\n",
       " 'dtt',\n",
       " 'dynamic exclusion',\n",
       " 'either 100 nl/min',\n",
       " 'exclusion duration',\n",
       " 'exclusion size',\n",
       " 'five most intense ions',\n",
       " 'flag-tagged full-length mdia2',\n",
       " 'flow',\n",
       " 'flow rate',\n",
       " 'fractions',\n",
       " 'gel',\n",
       " 'gel',\n",
       " 'generation',\n",
       " 'germany',\n",
       " 'gradient',\n",
       " 'hcd',\n",
       " 'hcd',\n",
       " 'hcd fragmentation',\n",
       " 'house',\n",
       " 'i.d',\n",
       " 'i.d',\n",
       " 'instrument',\n",
       " 'internal mass calibration',\n",
       " 'invitrogen',\n",
       " 'invitrogen',\n",
       " 'laemmli buffer',\n",
       " 'linear ion trap',\n",
       " 'lock',\n",
       " 'low mass cut-off',\n",
       " 'ltq orbitrap',\n",
       " 'ltq orbitrapvelos',\n",
       " 'manufacturer’s instructions',\n",
       " 'mass',\n",
       " 'mass spectrometer',\n",
       " 'mass spectrometry protein reduction',\n",
       " 'mdia2-based immunocomplexes and mass spectrometry 293t cells',\n",
       " 'merck',\n",
       " 'milli-q',\n",
       " 'millipore',\n",
       " 'ms',\n",
       " 'ms/ms',\n",
       " 'ms/ms event',\n",
       " 'nanolc',\n",
       " 'net buffer',\n",
       " 'night',\n",
       " 'normalized collision energy',\n",
       " 'nupage',\n",
       " 'one and a half milligrams',\n",
       " 'orbitrap',\n",
       " 'orbitrapvelos',\n",
       " 'peptides',\n",
       " 'positive ion mode',\n",
       " 'precursors',\n",
       " 'protease inhibitor cocktail',\n",
       " 'proteins',\n",
       " 'reprosil c18 analytical column',\n",
       " 'reprosil c18 trap column',\n",
       " 'resolution',\n",
       " 'roche',\n",
       " 'rt',\n",
       " 'samples',\n",
       " 'sds-page',\n",
       " 'sigma-aldrich',\n",
       " 'signal threshold',\n",
       " 'solvent a',\n",
       " 'solvent a',\n",
       " 'solvent b',\n",
       " 'survey scan',\n",
       " 'survey scan',\n",
       " 'target lock mass abundance',\n",
       " 'thermo scientific',\n",
       " 'three most intense ions',\n",
       " 'trapping',\n",
       " 'triton',\n",
       " 'trypsin',\n",
       " 'unknown charge state',\n",
       " 'which digestion']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(extract_noun_chuncks(test_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sec3-2'></a><b>2. Create DataFrame with Noun Chunks</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sample_protocol...\n",
      "Processing data_protocol...\n",
      "Processing description...\n",
      "CPU times: user 13min 35s, sys: 1min 43s, total: 15min 19s\n",
      "Wall time: 10min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# extrac noun_chunks from the text\n",
    "if True:\n",
    "    print('Processing sample_protocol...')\n",
    "    df.loc[:, 'sample_protocol'] = df.loc[:, 'sample_protocol'].apply(lambda x: extract_noun_chuncks(x))\n",
    "    \n",
    "    print('Processing data_protocol...')\n",
    "    df.loc[:, 'data_protocol'] = df.loc[:, 'data_protocol'].apply(lambda x: extract_noun_chuncks(x))\n",
    "    \n",
    "    print('Processing description...')\n",
    "    df.loc[:, 'description'] = df.loc[:, 'description'].apply(lambda x: extract_noun_chuncks(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_id</th>\n",
       "      <th>sample_protocol</th>\n",
       "      <th>data_protocol</th>\n",
       "      <th>description</th>\n",
       "      <th>instruments</th>\n",
       "      <th>exp_types</th>\n",
       "      <th>quant_methods</th>\n",
       "      <th>labhead_fullname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PXD000011</td>\n",
       "      <td>[crude membranes, 5 p56-p70 glun1tap/tap mouse...</td>\n",
       "      <td>[data-dependent, resolution, full ms spectrum,...</td>\n",
       "      <td>[tap-glun1, 840 kda, 1.5 mda, psd95-tap, 1.5 m...</td>\n",
       "      <td>LTQ Orbitrap, instrument model</td>\n",
       "      <td>Bottom-up proteomics</td>\n",
       "      <td>nan</td>\n",
       "      <td>Seth Grant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>PXD000029</td>\n",
       "      <td>[breast cancer tissue lysates, reduction, alky...</td>\n",
       "      <td>[proteomics data, proteome discoverer, fdr&lt;0.0...</td>\n",
       "      <td>[current prognostic factors, precise risk-disc...</td>\n",
       "      <td>LTQ Orbitrap Velos</td>\n",
       "      <td>Shotgun proteomics</td>\n",
       "      <td>iTRAQ</td>\n",
       "      <td>Pavel Bouchal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>PXD000041</td>\n",
       "      <td>[gel, standard protocols, sds-page, washing, e...</td>\n",
       "      <td>[resulting spectra, mascot™, matrix science, s...</td>\n",
       "      <td>[hrp3_purification, schizosaccharomyces pombe ...</td>\n",
       "      <td>LTQ Orbitrap, instrument model</td>\n",
       "      <td>Bottom-up proteomics</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>PXD000063</td>\n",
       "      <td>[conditioned media preparation, hplc-isobaric ...</td>\n",
       "      <td>[data analysis –, ab sciex, ms/ms spectra, pro...</td>\n",
       "      <td>[twenty million lbetat2 cells, either control,...</td>\n",
       "      <td>4800 Proteomics Analyzer</td>\n",
       "      <td>Bottom-up proteomics</td>\n",
       "      <td>nan</td>\n",
       "      <td>Stuart C. Sealfon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>PXD000115</td>\n",
       "      <td>[proteins, washed beads, 2-fold-concentrated s...</td>\n",
       "      <td>[raw files, software program maxquant, recalib...</td>\n",
       "      <td>[n-terminal protease npro, pestiviruses, innat...</td>\n",
       "      <td>LTQ Orbitrap, instrument model</td>\n",
       "      <td>Bottom-up proteomics</td>\n",
       "      <td>nan</td>\n",
       "      <td>Dr. Penny Powell</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset_id                                    sample_protocol  \\\n",
       "8   PXD000011  [crude membranes, 5 p56-p70 glun1tap/tap mouse...   \n",
       "23  PXD000029  [breast cancer tissue lysates, reduction, alky...   \n",
       "31  PXD000041  [gel, standard protocols, sds-page, washing, e...   \n",
       "50  PXD000063  [conditioned media preparation, hplc-isobaric ...   \n",
       "92  PXD000115  [proteins, washed beads, 2-fold-concentrated s...   \n",
       "\n",
       "                                        data_protocol  \\\n",
       "8   [data-dependent, resolution, full ms spectrum,...   \n",
       "23  [proteomics data, proteome discoverer, fdr<0.0...   \n",
       "31  [resulting spectra, mascot™, matrix science, s...   \n",
       "50  [data analysis –, ab sciex, ms/ms spectra, pro...   \n",
       "92  [raw files, software program maxquant, recalib...   \n",
       "\n",
       "                                          description  \\\n",
       "8   [tap-glun1, 840 kda, 1.5 mda, psd95-tap, 1.5 m...   \n",
       "23  [current prognostic factors, precise risk-disc...   \n",
       "31  [hrp3_purification, schizosaccharomyces pombe ...   \n",
       "50  [twenty million lbetat2 cells, either control,...   \n",
       "92  [n-terminal protease npro, pestiviruses, innat...   \n",
       "\n",
       "                       instruments             exp_types quant_methods  \\\n",
       "8   LTQ Orbitrap, instrument model  Bottom-up proteomics           nan   \n",
       "23              LTQ Orbitrap Velos    Shotgun proteomics         iTRAQ   \n",
       "31  LTQ Orbitrap, instrument model  Bottom-up proteomics           nan   \n",
       "50        4800 Proteomics Analyzer  Bottom-up proteomics           nan   \n",
       "92  LTQ Orbitrap, instrument model  Bottom-up proteomics           nan   \n",
       "\n",
       "     labhead_fullname  \n",
       "8          Seth Grant  \n",
       "23      Pavel Bouchal  \n",
       "31                nan  \n",
       "50  Stuart C. Sealfon  \n",
       "92   Dr. Penny Powell  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serialize and save the processed DF\n",
    "if True:\n",
    "    with open('nlp15_data/dfs/all_fields_nchunks_df.pickle', 'wb') as out_df:\n",
    "        pickle.dump(df, out_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sec4'></a>\n",
    "## 4. Create dummies for quant types\n",
    "<a href='#sec0'>(Back to top)</a><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    with open('nlp15_data/dfs/all_fields_nchunks_df.pickle', 'rb') as infile_df:\n",
    "        df = pickle.load(infile_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropna\n",
    "df.replace({'nan':np.NaN}, inplace=True)\n",
    "df = df.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "silac                                                   501\n",
       "ms1 intensity based label-free quantification method    345\n",
       "spectrum counting                                       328\n",
       "tmt                                                     292\n",
       "itraq                                                   274\n",
       "label free                                              240\n",
       "tic                                                     158\n",
       "normalized spectral abundance factor - nsaf              96\n",
       "peptide counting                                         48\n",
       "empai                                                    33\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# .lower() all the quant methods\n",
    "df.loc[:, 'quant_methods'] = df.quant_methods.str.lower()\n",
    "\n",
    "# Figure out which quant methods are most pouplar\n",
    "quant_methods_added_string = ','.join(list(df.quant_methods))\n",
    "methods_strings = [method.strip() for method in quant_methods_added_string.split(',')]\n",
    "methods_strings = pd.Series(methods_strings)\n",
    "\n",
    "methods_strings.value_counts()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    df['silac'] = df.quant_methods.str.contains('silac').astype(int)\n",
    "    df['ms1_label_free'] = df.quant_methods.str.contains('ms1 intensity based label-free quantification method').astype(int)\n",
    "    df['spectrum_counting'] = df.quant_methods.str.contains('spectrum counting').astype(int)\n",
    "    df['tmt'] = df.quant_methods.str.contains('tmt').astype(int)\n",
    "    df['itraq'] = df.quant_methods.str.contains('itraq').astype(int)\n",
    "    df['label_free'] = df.quant_methods.str.contains('label free').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_id</th>\n",
       "      <th>sample_protocol</th>\n",
       "      <th>data_protocol</th>\n",
       "      <th>description</th>\n",
       "      <th>instruments</th>\n",
       "      <th>exp_types</th>\n",
       "      <th>quant_methods</th>\n",
       "      <th>labhead_fullname</th>\n",
       "      <th>silac</th>\n",
       "      <th>ms1_label_free</th>\n",
       "      <th>spectrum_counting</th>\n",
       "      <th>tmt</th>\n",
       "      <th>itraq</th>\n",
       "      <th>label_free</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PXD000029</td>\n",
       "      <td>[breast cancer tissue lysates, reduction, alky...</td>\n",
       "      <td>[proteomics data, proteome discoverer, fdr&lt;0.0...</td>\n",
       "      <td>[current prognostic factors, precise risk-disc...</td>\n",
       "      <td>LTQ Orbitrap Velos</td>\n",
       "      <td>Shotgun proteomics</td>\n",
       "      <td>itraq</td>\n",
       "      <td>Pavel Bouchal</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PXD000164</td>\n",
       "      <td>[protein extraction, catheter biofilm small pi...</td>\n",
       "      <td>[tryptic digest, reversed phase, rp) chromatog...</td>\n",
       "      <td>[term-catheterization, catheter-associated bac...</td>\n",
       "      <td>LTQ Orbitrap Velos</td>\n",
       "      <td>Shotgun proteomics</td>\n",
       "      <td>label free</td>\n",
       "      <td>Katharina Riedel</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset_id                                    sample_protocol  \\\n",
       "0  PXD000029  [breast cancer tissue lysates, reduction, alky...   \n",
       "1  PXD000164  [protein extraction, catheter biofilm small pi...   \n",
       "\n",
       "                                       data_protocol  \\\n",
       "0  [proteomics data, proteome discoverer, fdr<0.0...   \n",
       "1  [tryptic digest, reversed phase, rp) chromatog...   \n",
       "\n",
       "                                         description         instruments  \\\n",
       "0  [current prognostic factors, precise risk-disc...  LTQ Orbitrap Velos   \n",
       "1  [term-catheterization, catheter-associated bac...  LTQ Orbitrap Velos   \n",
       "\n",
       "            exp_types quant_methods  labhead_fullname  silac  ms1_label_free  \\\n",
       "0  Shotgun proteomics         itraq     Pavel Bouchal      0               0   \n",
       "1  Shotgun proteomics    label free  Katharina Riedel      0               0   \n",
       "\n",
       "   spectrum_counting  tmt  itraq  label_free  \n",
       "0                  0    0      1           0  \n",
       "1                  0    0      0           1  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serialize and save the processed DF\n",
    "if True:\n",
    "    with open('nlp15_data/dfs/all_fields_nchunks_df_quant_dummies.pickle', 'wb') as out_df:\n",
    "        pickle.dump(df, out_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sec5'></a>\n",
    "## 5. Crate Dictionary and BoW & Tf-Idf corpora\n",
    "<a href='#sec0'>(Back to top)</a><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the corpora\n",
    "# This time I'll only use combined protocols and that combined with description field (i.e. two corpora) as in nlp13\n",
    "if True:\n",
    "    # Protocols combined\n",
    "    protocols_corpus = list(df.sample_protocol + df.data_protocol)\n",
    "    with open('nlp15_data/corpora/protocols_corpus_nchunks.pickle', 'wb') as outfile:\n",
    "        pickle.dump(protocols_corpus, outfile)\n",
    "\n",
    "    # All combined\n",
    "    whole_corpus = list(df.sample_protocol + df.data_protocol + df.description)\n",
    "    with open('nlp15_data/corpora/whole_corpus.pickle_nchunks', 'wb') as outfile:\n",
    "        pickle.dump(whole_corpus, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and save dictionary using whole_corpus\n",
    "if True:\n",
    "    my_dictionary = corpora.Dictionary(whole_corpus)\n",
    "    my_dictionary.save('nlp15_data/whole_dictionary_nchunks.dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save BoW and Tf-Idf\n",
    "if True:\n",
    "    # BoW transformations and save\n",
    "    protocols_bow = [my_dictionary.doc2bow(text) for text in protocols_corpus]\n",
    "    whole_bow = [my_dictionary.doc2bow(text) for text in whole_corpus]\n",
    "    corpora.MmCorpus.serialize('nlp15_data/bow_and_tfidf/protocols_bow_nchunks.mm', protocols_bow)\n",
    "    corpora.MmCorpus.serialize('nlp15_data/bow_and_tfidf/whole_bow_nchunks.mm', whole_bow)\n",
    "    \n",
    "    # Tf-Idf transformations  and save\n",
    "    protocols_tfidf_model = models.TfidfModel(protocols_bow)\n",
    "    protocols_tfidf = protocols_tfidf_model[protocols_bow]\n",
    "    corpora.MmCorpus.serialize('nlp15_data/bow_and_tfidf/protocols_tfidf_nchunks.mm', protocols_tfidf)\n",
    "    \n",
    "    whole_tfidf_model = models.TfidfModel(whole_bow)\n",
    "    whole_tfidf = whole_tfidf_model[whole_bow]\n",
    "    corpora.MmCorpus.serialize('nlp15_data/bow_and_tfidf/whole_tfidf_nchunks.mm', whole_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2387, 2387, 2387)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df), len(protocols_tfidf), len(whole_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### I think it's ok to end this notebook here and create another one for the actual analysis / classification procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
