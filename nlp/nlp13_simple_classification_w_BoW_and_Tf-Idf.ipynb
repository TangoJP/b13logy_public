{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive annotation of quantification methods\n",
    "Idea is to use the descriptive text for each dataset to predict which quantification method was used for the experiments for the dataset. Below is an outline for the process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation\n",
    "1. Read in the DataFrame.\n",
    "    - Use only sample- & data-processing protocols, description, title, and quantificationMethods columns\n",
    "    - apply .dropna() and see how many datasets remain\n",
    "2. Decide on how many classes of quantification methods to create.\n",
    "    - Apply .lower() to everything\n",
    "    - Pick top 4 or 5 and put others into other category.\n",
    "    - Create dummy variables for the picked categories\n",
    "    - Some data sets contain multiple quant methods, so I'll focus on binary classification for each dummy for now\n",
    "3. Pre-process text fields for NLP\n",
    "    - They all have to be processed the same way\n",
    "    - Remove stop words, punctuation including brackets, non-aphanumericals\n",
    "    - Lemmatize\n",
    "4. Save processed data\n",
    "    - Save DataFrame with dummies and pre-processed text\n",
    "    - Create 6 sets of pre-processed text this will be used for creating dictionaries/models (e.g. BoW, Tf-Idf)\n",
    "        - Sample preparation protocol only\n",
    "        - Data processing protocol only\n",
    "        - Title only\n",
    "        - Description protocol only\n",
    "        - Sample + data protocols\n",
    "        - All fields combined\n",
    "    - All to be saved under /serialized_data directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLP\n",
    "For now, only use BoW (counts) and Tf-Idf vectors. Some useless words can be potentially ommitted using feature_importance_ attribute of sklearn classifiers later, and then leaner dictionary could be used to create more informative, lower-dimensional feature space (hopefully).\n",
    "1. Save each corpus via Gensim\n",
    "2. Create a dictionary using the text set with all fields combined\n",
    "3. Create BoWs for all text sets, save them\n",
    "4. Create Tf-Idf for all text sets, save them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification\n",
    "Here, I'll focus on binary classification for each category. For example, it'll be 'silac' vs everything else. Ideally, it should be multi-class classification, but since a dataset can contain multiple quantification methods, for now, I'll stick with yes/no type binary classification for each quantification method that I picked.<br>\n",
    "<br>\n",
    "Classifiers to try: Naive Bayes, Logistic Regression, Random Forest (and SVM maybe?)<br>\n",
    "<br>\n",
    "For each classifier for each quantification type:<br>\n",
    "1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
